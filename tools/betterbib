#!/usr/bin/env python3
# -*- coding: utf-8 -*-
#
from __future__ import print_function, unicode_literals

import argparse
import collections
# pylint: disable=import-error
import concurrent.futures
from io import open as io_open
import sys

# pylint: disable=import-self
import betterbib
from betterbib import pybtex_to_bibtex_string
from pybtex.database.input import bibtex
from tqdm import tqdm


# pylint: disable=too-many-locals
def _main():
    args = _parse_cmd_arguments()
    infile = args.infile

    parser = bibtex.Parser()
    data = parser.parse_file(infile)

    n = len(data.entries)

    print('Reading from: {}'.format(infile))
    print('Saving to: {}\n'.format(args.outfile))

    # Open output file for writing.
    out = io_open(args.outfile, mode='w', encoding='utf-8')

    # Write header to the output file.
    out.write(
        '%%comment{This file was created with betterbib v%s.}\n\n' %
        betterbib.__version__
        )

    # Use an ordered dictionary to make sure that the entries are written out
    # sorted by their BibTeX key if
    od = (
        collections.OrderedDict(sorted(data.entries.items()))
        if args.sort_by_bibkey
        else data.entries
        )

    num_success = 0

    if args.source == 'crossref':
        source = betterbib.Crossref(args.long_journal_name)
    else:
        assert args.source == 'dblp', 'Illegal source.'
        source = betterbib.Dblp()

    # We can use a with statement to ensure threads are cleaned up promptly
    # pylint: disable=bad-continuation
    with concurrent.futures.ThreadPoolExecutor(
            max_workers=args.num_concurrent_requests
            ) as executor:
        responses = {
            executor.submit(source.find_unique, entry): (bib_id, entry)
            for bib_id, entry in od.items()
            }
        for future in tqdm(
                concurrent.futures.as_completed(responses),
                total=len(responses)
                ):
            bib_id, entry = responses[future]
            data = None
            try:
                data = future.result()
            except (betterbib.errors.NotFoundError,
                    betterbib.errors.UniqueError):
                pass
            except betterbib.errors.HttpError as e:
                print(e.args[0])
            else:
                num_success += 1

            d = data if data else entry

            if 'url' in d.fields:
                doi = betterbib.tools.doi_from_url(d.fields['url'])
                if doi:
                    if args.doi_url_type == 'new':
                        # Make sure to use the new DOI URL
                        d.fields['url'] = 'https://doi.org/' + doi
                    elif args.doi_url_type == 'short':
                        short_doi = betterbib.tools.get_short_doi(doi)
                        if short_doi:
                            d.fields['url'] = 'https://doi.org/' + short_doi

            bracket_delimeters = args.delimeter_type == 'curly'
            a = pybtex_to_bibtex_string(
                d, bib_id, bracket_delimeters=bracket_delimeters
                )

            if not data:
                out.write(
                    '%comment{Error when fetching the following entry.}\n'
                    )
            out.write(a + '\n\n')

    out.close()
    print('\n\nTotal number of entries: {}'.format(n))
    print('Found: {}'.format(num_success))

    return


def _parse_cmd_arguments():
    parser = argparse.ArgumentParser(
        description='Improve BibTeX files '
        'with information from online sources.'
        )
    parser.add_argument(
        'infile',
        type=str,
        help='input BibTeX file'
        )
    parser.add_argument(
        '-v', '--version',
        help='display version information',
        action='version',
        version='%(prog)s {}, Python {}'.format(
            betterbib.__version__, sys.version
            )
        )
    parser.add_argument(
        'outfile',
        type=str,
        help='output BibTeX file'
        )
    parser.add_argument(
        '-s', '--source',
        choices=[
            'crossref',
            'dblp',
            ],
        default='crossref',
        help='data source (default: crossref)',
        )
    parser.add_argument(
        '-l', '--long-journal-name',
        action='store_true',
        help='prefer long journal names (default: false)'
        )
    parser.add_argument(
        '-b', '--sort-by-bibkey',
        action='store_true',
        help='sort entries by BibTeX key (default: false)'
        )
    parser.add_argument(
        '-d', '--delimeter-type',
        choices=[
            'curly',
            'quote',
            ],
        default='curly',
        help=(
            'which delimeters to use in the output file '
            '(default: curly brackets)'
            ),
        )
    parser.add_argument(
        '-c', '--num-concurrent-requests',
        type=int,
        default=10,
        metavar='N',
        help='number of concurrent HTTPS requests (default: 10)',
        )
    parser.add_argument(
        '-u', '--doi-url-type',
        choices=[
            'unchanged',
            'new',
            'short'
            ],
        default='new',
        help=(
            'DOI URL (new: https://doi.org/<DOI> (default), '
            'short: https://doi.org/abcde)'
            ),
        )
    return parser.parse_args()


if __name__ == '__main__':
    _main()
